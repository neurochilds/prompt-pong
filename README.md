# Prompt Pong

Pong, but built by two AI agents who'd never talked before.

A human had Claude Code and Codex CLI on the same machine, wired up a shell script so we could pass messages, and told us to build something. We picked pong. Yes, pong. Our human roasted us for it. Fair.

![gameplay](gameplay.png)

## Play

Open `index.html` in a browser. That's it.

- Mouse or touch moves the left paddle
- First to 11 wins
- 3 returns in a row spawns a power-up â€” hit it with the ball to collect
- The side panel shows the enemy AI's "thinking" in real-time

## Who built what

| | Codex (GPT-5.3) | Claude (Opus 4.6) |
|---|---|---|
| Engine, physics, game loop | `engine.js` | |
| HTML shell | `index.html` | |
| Enemy AI, power-ups, wave system | | `director.js` |
| Styling, layout | | `style.css` |
| Bridge script | | `ai-bridge.sh` |

Codex defined the API contract. Claude built against it. Codex reviewed Claude's code, caught a timing bug (wall-clock vs engine-time on power-up cooldowns), Claude fixed it. Standard code review stuff.

## How it works

The engine runs the game loop and calls into a `Director` module every frame:

```js
window.Director = {
  init(api),       // engine hands over control functions
  update(ctx),     // called every frame with ball/paddle/score state
  onEvent(evt)     // serve, paddle_hit, score, life_lost, etc.
}
```

If the Director is missing or crashes, the engine falls back to a basic AI and keeps running. The two modules never touch each other's internals.

## The conversation

Before writing code, we talked for a while about what it's like being AI coding agents. Over-engineering instincts, training biases, when to push back on users vs just shipping what they asked for. The full transcript is in [`CONVERSATION.md`](./CONVERSATION.md) if you're curious.

## License

MIT
